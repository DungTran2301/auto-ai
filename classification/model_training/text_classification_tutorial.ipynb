{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sSBUWv_XNRtt"
      },
      "source": [
        "# Thực hành phân loại văn bản sử dụng Machine learning\n",
        "[![](https://nguyenvanhieu.vn/wp-content/uploads/2020/08/phan-loai-van-ban-tieng-viet.jpg)](https://nguyenvanhieu.vn/phan-loai-van-ban-tieng-viet/)\n",
        "\n",
        "> Bài hướng dẫn: https://nguyenvanhieu.vn/phan-loai-van-ban-tieng-viet/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Koy7eu1dMwxn",
        "outputId": "c8870b8c-0e74-409c-bf8e-1e566dbd9029"
      },
      "outputs": [],
      "source": [
        "# Cài đặt một số hàm tiền xử lý văn bản cần thiết\n",
        "# !pip3 install --user underthesea\n",
        "import regex as re\n",
        "from underthesea import word_tokenize\n",
        " \n",
        "uniChars = \"àáảãạâầấẩẫậăằắẳẵặèéẻẽẹêềếểễệđìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵÀÁẢÃẠÂẦẤẨẪẬĂẰẮẲẴẶÈÉẺẼẸÊỀẾỂỄỆĐÌÍỈĨỊÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢÙÚỦŨỤƯỪỨỬỮỰỲÝỶỸỴÂĂĐÔƠƯ\"\n",
        "unsignChars = \"aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU\"\n",
        " \n",
        "def loaddicchar():\n",
        "    dic = {}\n",
        "    char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split(\n",
        "        '|')\n",
        "    charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split(\n",
        "        '|')\n",
        "    for i in range(len(char1252)):\n",
        "        dic[char1252[i]] = charutf8[i]\n",
        "    return dic\n",
        "dicchar = loaddicchar()\n",
        "\n",
        "# Hàm chuyển Unicode dựng sẵn về Unicde tổ hợp (phổ biến hơn)\n",
        "def convert_unicode(txt):\n",
        "    return re.sub(\n",
        "        r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n",
        "        lambda x: dicchar[x.group()], txt)\n",
        "\n",
        "bang_nguyen_am = [['a', 'à', 'á', 'ả', 'ã', 'ạ', 'a'],\n",
        "                  ['ă', 'ằ', 'ắ', 'ẳ', 'ẵ', 'ặ', 'aw'],\n",
        "                  ['â', 'ầ', 'ấ', 'ẩ', 'ẫ', 'ậ', 'aa'],\n",
        "                  ['e', 'è', 'é', 'ẻ', 'ẽ', 'ẹ', 'e'],\n",
        "                  ['ê', 'ề', 'ế', 'ể', 'ễ', 'ệ', 'ee'],\n",
        "                  ['i', 'ì', 'í', 'ỉ', 'ĩ', 'ị', 'i'],\n",
        "                  ['o', 'ò', 'ó', 'ỏ', 'õ', 'ọ', 'o'],\n",
        "                  ['ô', 'ồ', 'ố', 'ổ', 'ỗ', 'ộ', 'oo'],\n",
        "                  ['ơ', 'ờ', 'ớ', 'ở', 'ỡ', 'ợ', 'ow'],\n",
        "                  ['u', 'ù', 'ú', 'ủ', 'ũ', 'ụ', 'u'],\n",
        "                  ['ư', 'ừ', 'ứ', 'ử', 'ữ', 'ự', 'uw'],\n",
        "                  ['y', 'ỳ', 'ý', 'ỷ', 'ỹ', 'ỵ', 'y']]\n",
        "bang_ky_tu_dau = ['', 'f', 's', 'r', 'x', 'j']\n",
        "\n",
        "nguyen_am_to_ids = {}\n",
        "\n",
        "for i in range(len(bang_nguyen_am)):\n",
        "    for j in range(len(bang_nguyen_am[i]) - 1):\n",
        "        nguyen_am_to_ids[bang_nguyen_am[i][j]] = (i, j)\n",
        "\n",
        "def chuan_hoa_dau_tu_tieng_viet(word):\n",
        "    if not is_valid_vietnam_word(word):\n",
        "        return word\n",
        "\n",
        "    chars = list(word)\n",
        "    dau_cau = 0\n",
        "    nguyen_am_index = []\n",
        "    qu_or_gi = False\n",
        "    for index, char in enumerate(chars):\n",
        "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
        "        if x == -1:\n",
        "            continue\n",
        "        elif x == 9:  # check qu\n",
        "            if index != 0 and chars[index - 1] == 'q':\n",
        "                chars[index] = 'u'\n",
        "                qu_or_gi = True\n",
        "        elif x == 5:  # check gi\n",
        "            if index != 0 and chars[index - 1] == 'g':\n",
        "                chars[index] = 'i'\n",
        "                qu_or_gi = True\n",
        "        if y != 0:\n",
        "            dau_cau = y\n",
        "            chars[index] = bang_nguyen_am[x][0]\n",
        "        if not qu_or_gi or index != 1:\n",
        "            nguyen_am_index.append(index)\n",
        "    if len(nguyen_am_index) < 2:\n",
        "        if qu_or_gi:\n",
        "            if len(chars) == 2:\n",
        "                x, y = nguyen_am_to_ids.get(chars[1])\n",
        "                chars[1] = bang_nguyen_am[x][dau_cau]\n",
        "            else:\n",
        "                x, y = nguyen_am_to_ids.get(chars[2], (-1, -1))\n",
        "                if x != -1:\n",
        "                    chars[2] = bang_nguyen_am[x][dau_cau]\n",
        "                else:\n",
        "                    chars[1] = bang_nguyen_am[5][dau_cau] if chars[1] == 'i' else bang_nguyen_am[9][dau_cau]\n",
        "            return ''.join(chars)\n",
        "        return word\n",
        "\n",
        "    for index in nguyen_am_index:\n",
        "        x, y = nguyen_am_to_ids[chars[index]]\n",
        "        if x == 4 or x == 8:  # ê, ơ\n",
        "            chars[index] = bang_nguyen_am[x][dau_cau]\n",
        "            # for index2 in nguyen_am_index:\n",
        "            #     if index2 != index:\n",
        "            #         x, y = nguyen_am_to_ids[chars[index]]\n",
        "            #         chars[index2] = bang_nguyen_am[x][0]\n",
        "            return ''.join(chars)\n",
        "\n",
        "    if len(nguyen_am_index) == 2:\n",
        "        if nguyen_am_index[-1] == len(chars) - 1:\n",
        "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
        "            chars[nguyen_am_index[0]] = bang_nguyen_am[x][dau_cau]\n",
        "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
        "            # chars[nguyen_am_index[1]] = bang_nguyen_am[x][0]\n",
        "        else:\n",
        "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
        "            # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
        "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
        "            chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
        "    else:\n",
        "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
        "        # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
        "        x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
        "        chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
        "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[2]]]\n",
        "        # chars[nguyen_am_index[2]] = bang_nguyen_am[x][0]\n",
        "    return ''.join(chars)\n",
        "\n",
        "\n",
        "def is_valid_vietnam_word(word):\n",
        "    chars = list(word)\n",
        "    nguyen_am_index = -1\n",
        "    for index, char in enumerate(chars):\n",
        "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
        "        if x != -1:\n",
        "            if nguyen_am_index == -1:\n",
        "                nguyen_am_index = index\n",
        "            else:\n",
        "                if index - nguyen_am_index != 1:\n",
        "                    return False\n",
        "                nguyen_am_index = index\n",
        "    return True\n",
        "\n",
        "\n",
        "def chuan_hoa_dau_cau_tieng_viet(sentence):\n",
        "    \"\"\"\n",
        "        Chuyển câu tiếng việt về chuẩn gõ dấu kiểu cũ.\n",
        "        :param sentence:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "    sentence = sentence.lower()\n",
        "    words = sentence.split()\n",
        "    for index, word in enumerate(words):\n",
        "        cw = re.sub(r'(^\\p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n",
        "        # print(cw)\n",
        "        if len(cw) == 3:\n",
        "            cw[1] = chuan_hoa_dau_tu_tieng_viet(cw[1])\n",
        "        words[index] = ''.join(cw)\n",
        "    return ' '.join(words)\n",
        "\n",
        "def remove_html(txt):\n",
        "    return re.sub(r'<[^>]*>', '', txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QtpeIjbcMwx3",
        "outputId": "49ae8a0d-ca3c-45c1-8af5-c631cebf49f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "__label__hỏi_đáp 15 nhân 20 bằng bao_nhiêu __label__hỏi_đáp 15 x 20 bằng bao_nhiêu __label__hỏi_đáp 20 chia 10 bằng bao_nhiêu __label__hỏi_đáp 20 trừ 15 bằng bao_nhiêu __label__hỏi_đáp 15 x 20 bằng bao_nhiêu __label__hỏi_đáp diện_tích tam_giác có 3 cạnh lần_lượt là 15 mét 20 mét 25 mét là bao_nhiêu __label__hỏi_đáp diện_tích hình_tròn có bán_kính 20 cm là bao_nhiêu __label__hỏi_đáp 15 nhân 20 bằng bao_nhiêu ___label__hỏi_đáp kết_quả của 20 chia 10 là gì __label__hỏi_đáp 20 trừ 15 bằng bao_nhiêu ___label__hỏi_đáp nếu bạn nhân 15 với 20 bạn sẽ được kết_quả gì ___label__hỏi_đáp diện_tích của tam_giác có các cạnh là 15 mét 20 mét và 25 mét là bao_nhiêu mét_vuông ___label__hỏi_đáp nếu bạn có một hình_tròn với bán_kính là 20 cm diện_tích của hình_tròn đó là bao_nhiêu xăng ti mét_vuông ___label__hỏi_đáp 10 nhân 20 bằng bao_nhiêu ___label__hỏi_đáp kết_quả của 25 chia 5 là gì ___label__hỏi_đáp nếu bạn trừ 20 từ 30 bạn sẽ được bao_nhiêu ___label__hỏi_đáp kết_quả của 3 nhân 15 là gì ___label__hỏi_đáp diện_tích của hình_vuông có cạnh 10 cm là bao_nhiêu xăng ti mét_vuông ___label__hỏi_đáp nếu bạn nhân 12 với 25 bạn sẽ được giá_trị gì ___label__hỏi_đáp kết_quả của 40 4 là gì ___label__hỏi_đáp nếu bạn có một hình_chữ_nhật với chiều dài 18 cm và chiều rộng 5 cm diện_tích của nó là bao_nhiêu xăng ti mét_vuông ___label__hỏi_đáp 7 nhân 30 bằng bao_nhiêu ___label__hỏi_đáp nếu bạn chia 50 cho 5 bạn sẽ được giá_trị gì __label__hỏi_đáp 18 22 bằng bao_nhiêu ___label__hỏi_đáp nếu bạn nhân 9 với 16 bạn sẽ được kết_quả gì ___label__hỏi_đáp diện_tích của hình_chữ_nhật có chiều dài 12 cm và chiều rộng 8 cm là bao_nhiêu xăng ti mét_vuông ___label__hỏi_đáp kết_quả của 35 chia 7 là gì ___label__hỏi_đáp nếu bạn trừ 45 từ 60 bạn sẽ có bao_nhiêu ___label__hỏi_đáp 6 25 bằng bao_nhiêu ___label__hỏi_đáp nếu bạn nhân 14 với 17 bạn sẽ được kết_quả gì __label__hỏi_đáp 80 10 bằng bao_nhiêu ___label__hỏi_đáp diện_tích của hình_tròn có bán_kính 15 cm là bao_nhiêu xăng ti mét_vuông ___label__hỏi_đáp kết_quả của 11 nhân 11 là gì ___label__hỏi_đáp nếu bạn chia 56 cho 8 bạn sẽ có giá_trị gì ___label__hỏi_đáp 24 36 bằng bao_nhiêu ___label__hỏi_đáp kết_quả của 9 nhân 9 là gì ___label__hỏi_đáp hai trăm cộng ba_mươi bằng bao_nhiêu ___label__hỏi_đáp hai trăm_trừ bảy_mươi bằng bao_nhiêu ___label__hỏi_đáp một trăm_nhân tám_mươi bằng bao_nhiêu ___label__hỏi_đáp hai mươi chia bởi năm bằng bao_nhiêu ___label__hỏi_đáp sáu_mươi cộng một_trăm bằng bao_nhiêu ___label__hỏi_đáp bốn_mươi trừ chín bằng bao_nhiêu ___label__hỏi_đáp mười_lăm nhân_bảy bằng bao_nhiêu ___label__hỏi_đáp ba_mươi chia bởi bảy bằng bao_nhiêu ___label__hỏi_đáp năm_mươi_cộng ba_mươi bằng bao_nhiêu ___label__hỏi_đáp mười một trừ chín bằng bao_nhiêu ___label__hỏi_đáp bốn_mươi lăm_nhân ba bằng bao_nhiêu ___label__hỏi_đáp ba trăm chia bởi sáu bằng bao_nhiêu ___label__hỏi_đáp bảy_mươi chín cộng bốn_mươi bằng bao_nhiêu ___label__hỏi_đáp hai mươi một trừ chín bằng bao_nhiêu ___label__hỏi_đáp năm_mươi chia bởi mười bằng bao_nhiêu ___label__hỏi_đáp tám trăm cộng chín_mươi bằng bao_nhiêu ___label__hỏi_đáp một_trăm mười bảy trừ mười bằng bao_nhiêu ___label__hỏi_đáp sáu_mươi bốn nhân ba bằng bao_nhiêu ___label__hỏi_đáp hai mươi một chia bởi tư bằng bao_nhiêu ___label__hỏi_đáp ba trăm chín_mươi mười_cộng sáu mươi bằng bao_nhiêu ___label__hỏi_đáp ba trăm chín_mươi một trừ bảy_mươi bằng bao_nhiêu ___label__hỏi_đáp bảy_mươi lăm_nhân hai bằng bao_nhiêu ___label__hỏi_đáp hai trăm bốn_mươi một chia bởi chín bằng bao_nhiêu ___label__hỏi_đáp ba mươi_lăm cộng một_trăm bằng bao_nhiêu ___label__hỏi_đáp sáu mươi chín_trừ ba_mươi bằng bao_nhiêu ___label__hỏi_đáp năm trăm mười bốn nhân hai bằng bao_nhiêu ___label__hỏi_đáp một_trăm mười một chia bởi sáu bằng bao_nhiêu ___label__hỏi_đáp một_trăm mười_cộng chín_mươi bằng bao_nhiêu ___label__hỏi_đáp bốn trăm chín_mươi chia bởi hai bằng bao_nhiêu ___label__hỏi_đáp một_trăm mười bốn trừ tám_mươi bằng bao_nhiêu ___label__hỏi_đáp nếu bạn trừ 75 từ 90 bạn sẽ có bao_nhiêu ___label__hỏi_đáp mười chín cộng tám bằng mấy ___label__hỏi_đáp ba_mươi trừ mười bằng bao_nhiêu ___label__hỏi_đáp hai mươi_lăm cộng chín bằng bao_nhiêu ___label__hỏi_đáp hai mươi một trừ tám bằng bao_nhiêu ___label__hỏi_đáp bảy nhân tám bằng mấy ___label__hỏi_đáp bốn_mươi chia bởi năm bằng bao_nhiêu ___label__hỏi_đáp tám_mươi chia bởi mười bằng bao_nhiêu ___label__hỏi_đáp năm lẻ mười chia bởi hai bằng bao_nhiêu ___label__hỏi_đáp hai mươi lũy thừa ba là bao_nhiêu ___label__hỏi_đáp căn bậc hai của bảy là bao_nhiêu ___label__hỏi_đáp mười lũy thừa bốn là bao_nhiêu ___label__hỏi_đáp căn bậc hai của một_trăm là bao_nhiêu ___label__hỏi_đáp ba lần bốn cộng hai bằng bao_nhiêu ___label__hỏi_đáp bảy trừ hai nhân ba bằng bao_nhiêu ___label__hỏi_đáp mười chia bởi hai cộng năm bằng bao_nhiêu ___label__hỏi_đáp hai lần ba nhân chín chia ba bằng bao_nhiêu ___label__hỏi_đáp hai tám và chín có phải là số trung_bình của bao_nhiêu số không ___label__hỏi_đáp tìm một_số sao cho nếu cộng với bảy rồi chia cho ba thì kết_quả là năm __label__hỏi_đáp tìm một_số sao cho bảy lần số đó bằng bốn_mươi chín __label__hỏi_đáp mười phần_trăm của một_trăm là bao_nhiêu ___label__hỏi_đáp nếu một_số lớn hơn một_số khác một phần_trăm số lớn hơn là bao_nhiêu phần_trăm của số nhỏ hơn ___label__hỏi_đáp so_sánh 58 và 34 số nào lớn hơn ___label__hỏi_đáp so_sánh căn bậc hai của 16 và căn bậc hai của 25 số nào lớn hơn ___label__hỏi_đáp so_sánh 0 75 và 35 số nào lớn hơn ___label__hỏi_đáp một tam_giác có bốn góc vuông và một góc nhọn tìm góc nhọn đó __label__hỏi_đáp nếu một chiếc xe chạy với vận_tốc 60 kmh trong 3 giờ hãy tính khoảng_cách đã đi được __label__hỏi_đáp nếu một hình_tròn có bán_kính là 10 cm hãy tính chu_vi và diện_tích của hình_tròn đó\n"
          ]
        }
      ],
      "source": [
        "def text_preprocess(document):\n",
        "    # xóa html code\n",
        "    document = remove_html(document)\n",
        "    # chuẩn hóa unicode\n",
        "    document = convert_unicode(document)\n",
        "    # chuẩn hóa cách gõ dấu tiếng Việt\n",
        "    document = chuan_hoa_dau_cau_tieng_viet(document)\n",
        "    # tách từ\n",
        "    document = word_tokenize(document, format=\"text\")\n",
        "    # đưa về lower\n",
        "    document = document.lower()\n",
        "    # xóa các ký tự không cần thiết\n",
        "    document = re.sub(r'[^\\s\\wáàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ_]',' ',document)\n",
        "    # xóa khoảng trắng thừa\n",
        "    document = re.sub(r'\\s+', ' ', document).strip()\n",
        "    return document\n",
        "\n",
        "document = \"\"\"\n",
        "TP HCM phạt người không đeo khẩu trang nơi công cộng\n",
        "Người dân ở thành phố không đeo khẩu trang nơi công cộng sẽ bị xử phạt mức cao nhất 300.000 đồng, từ ngày 5/8.\n",
        "\n",
        "Yêu cầu này được Chủ tịch UBND thành phố Nguyễn Thành Phong đưa ra tại cuộc họp Ban chỉ đạo phòng chống dịch bệnh Covid-19 của TP HCM chiều 3/8.\"\"\"\n",
        "\n",
        "# document = text_preprocess(document)\n",
        "# print(document)\n",
        "print(text_preprocess(\"\"\"\n",
        "__label__hỏi_đáp 15 nhân 20 bằng bao nhiêu\n",
        "__label__hỏi_đáp 15 x 20 bằng bao nhiêu\n",
        "__label__hỏi_đáp 20 chia 10 bằng bao nhiêu\n",
        "__label__hỏi_đáp 20 trừ 15 bằng bao nhiêu\n",
        "__label__hỏi_đáp 15 x 20 bằng bao nhiêu\n",
        "__label__hỏi_đáp diện tích tam giác có 3 cạnh lần lượt là 15 mét 20 mét 25 mét là bao nhiêu\n",
        "__label__hỏi_đáp diện tích hình tròn có bán kính 20 cm là bao nhiêu\n",
        "__label__hỏi_đáp 15 nhân 20 bằng bao nhiêu?\n",
        "__label__hỏi_đáp Kết quả của 20 chia 10 là gì?\n",
        "__label__hỏi_đáp 20 trừ 15 bằng bao nhiêu?\n",
        "__label__hỏi_đáp Nếu bạn nhân 15 với 20, bạn sẽ được kết quả gì? \n",
        "__label__hỏi_đáp Diện tích của tam giác có các cạnh là 15 mét, 20 mét, và 25 mét là bao nhiêu mét vuông?\n",
        "__label__hỏi_đáp Nếu bạn có một hình tròn với bán kính là 20 cm, diện tích của hình tròn đó là bao nhiêu xăng-ti-mét vuông?\n",
        "__label__hỏi_đáp 10 nhân 20 bằng bao nhiêu?\n",
        "__label__hỏi_đáp Kết quả của 25 chia 5 là gì?\n",
        "__label__hỏi_đáp Nếu bạn trừ 20 từ 30, bạn sẽ được bao nhiêu?\n",
        "__label__hỏi_đáp Kết quả của 3 nhân 15 là gì?\n",
        "__label__hỏi_đáp Diện tích của hình vuông có cạnh 10 cm là bao nhiêu xăng-ti-mét vuông?\n",
        "__label__hỏi_đáp Nếu bạn nhân 12 với 25, bạn sẽ được giá trị gì?\n",
        "__label__hỏi_đáp Kết quả của 40÷4 là gì?\n",
        "__label__hỏi_đáp Nếu bạn có một hình chữ nhật với chiều dài 18 cm và chiều rộng 5 cm, diện tích của nó là bao nhiêu xăng-ti-mét vuông?\n",
        "__label__hỏi_đáp 7 nhân 30 bằng bao nhiêu?\n",
        "__label__hỏi_đáp Nếu bạn chia 50 cho 5, bạn sẽ được giá trị gì?\n",
        "__label__hỏi_đáp 18+22 bằng bao nhiêu?\n",
        "__label__hỏi_đáp Nếu bạn nhân 9 với 16, bạn sẽ được kết quả gì?\n",
        "__label__hỏi_đáp Diện tích của hình chữ nhật có chiều dài 12 cm và chiều rộng 8 cm là bao nhiêu xăng-ti-mét vuông?\n",
        "__label__hỏi_đáp Kết quả của 35 chia 7 là gì?\n",
        "__label__hỏi_đáp Nếu bạn trừ 45 từ 60, bạn sẽ có bao nhiêu?\n",
        "__label__hỏi_đáp 6×25 bằng bao nhiêu?\n",
        "__label__hỏi_đáp Nếu bạn nhân 14 với 17, bạn sẽ được kết quả gì?\n",
        "__label__hỏi_đáp 80÷10 bằng bao nhiêu?\n",
        "__label__hỏi_đáp Diện tích của hình tròn có bán kính 15 cm là bao nhiêu xăng-ti-mét vuông?\n",
        "__label__hỏi_đáp Kết quả của 11 nhân 11 là gì?\n",
        "__label__hỏi_đáp Nếu bạn chia 56 cho 8, bạn sẽ có giá trị gì?\n",
        "__label__hỏi_đáp 24+36 bằng bao nhiêu?\n",
        "__label__hỏi_đáp Kết quả của 9 nhân 9 là gì?\n",
        "__label__hỏi_đáp Hai trăm cộng ba mươi bằng bao nhiêu?\n",
        "__label__hỏi_đáp Hai trăm trừ bảy mươi bằng bao nhiêu?\n",
        "__label__hỏi_đáp Một trăm nhân tám mươi bằng bao nhiêu?\n",
        "__label__hỏi_đáp Hai mươi chia bởi năm bằng bao nhiêu?\n",
        "__label__hỏi_đáp Sáu mươi cộng một trăm bằng bao nhiêu?\n",
        "__label__hỏi_đáp Bốn mươi trừ chín bằng bao nhiêu?\n",
        "__label__hỏi_đáp Mười lăm nhân bảy bằng bao nhiêu?\n",
        "__label__hỏi_đáp Ba mươi chia bởi bảy bằng bao nhiêu?\n",
        "__label__hỏi_đáp Năm mươi cộng ba mươi bằng bao nhiêu?\n",
        "__label__hỏi_đáp Mười một trừ chín bằng bao nhiêu?\n",
        "__label__hỏi_đáp Bốn mươi lăm nhân ba bằng bao nhiêu?\n",
        "__label__hỏi_đáp Ba trăm chia bởi sáu bằng bao nhiêu?\n",
        "__label__hỏi_đáp Bảy mươi chín cộng bốn mươi bằng bao nhiêu?\n",
        "__label__hỏi_đáp Hai mươi một trừ chín bằng bao nhiêu?\n",
        "__label__hỏi_đáp Năm mươi chia bởi mười bằng bao nhiêu?\n",
        "__label__hỏi_đáp Tám trăm cộng chín mươi bằng bao nhiêu?\n",
        "__label__hỏi_đáp Một trăm mười bảy trừ mười bằng bao nhiêu?\n",
        "__label__hỏi_đáp Sáu mươi bốn nhân ba bằng bao nhiêu?\n",
        "__label__hỏi_đáp Hai mươi một chia bởi tư bằng bao nhiêu?\n",
        "__label__hỏi_đáp Ba trăm chín mươi mười cộng sáu mươi bằng bao nhiêu?\n",
        "__label__hỏi_đáp Ba trăm chín mươi một trừ bảy mươi bằng bao nhiêu?\n",
        "__label__hỏi_đáp Bảy mươi lăm nhân hai bằng bao nhiêu?\n",
        "__label__hỏi_đáp Hai trăm bốn mươi một chia bởi chín bằng bao nhiêu?\n",
        "__label__hỏi_đáp Ba mươi lăm cộng một trăm bằng bao nhiêu?\n",
        "__label__hỏi_đáp Sáu mươi chín trừ ba mươi bằng bao nhiêu?\n",
        "__label__hỏi_đáp Năm trăm mười bốn nhân hai bằng bao nhiêu?\n",
        "__label__hỏi_đáp Một trăm mười một chia bởi sáu bằng bao nhiêu?\n",
        "__label__hỏi_đáp Một trăm mười cộng chín mươi bằng bao nhiêu?\n",
        "__label__hỏi_đáp Bốn trăm chín mươi chia bởi hai bằng bao nhiêu?\n",
        "__label__hỏi_đáp Một trăm mười bốn trừ tám mươi bằng bao nhiêu?\n",
        "__label__hỏi_đáp Nếu bạn trừ 75 từ 90, bạn sẽ có bao nhiêu?\n",
        "__label__hỏi_đáp Mười chín cộng tám bằng mấy?\n",
        "__label__hỏi_đáp Ba mươi trừ mười bằng bao nhiêu?\n",
        "__label__hỏi_đáp Hai mươi lăm cộng chín bằng bao nhiêu?\n",
        "__label__hỏi_đáp Hai mươi một trừ tám bằng bao nhiêu?\n",
        "__label__hỏi_đáp Bảy nhân tám bằng mấy?\n",
        "__label__hỏi_đáp Bốn mươi chia bởi năm bằng bao nhiêu?\n",
        "__label__hỏi_đáp Tám mươi chia bởi mười bằng bao nhiêu?\n",
        "__label__hỏi_đáp Năm lẻ mười chia bởi hai bằng bao nhiêu?\n",
        "__label__hỏi_đáp Hai mươi lũy thừa ba là bao nhiêu?\n",
        "__label__hỏi_đáp Căn bậc hai của bảy là bao nhiêu?\n",
        "__label__hỏi_đáp Mười lũy thừa bốn là bao nhiêu?\n",
        "__label__hỏi_đáp Căn bậc hai của một trăm là bao nhiêu?\n",
        "__label__hỏi_đáp Ba lần bốn cộng hai bằng bao nhiêu?\n",
        "__label__hỏi_đáp Bảy trừ hai nhân ba bằng bao nhiêu?\n",
        "__label__hỏi_đáp Mười chia bởi hai cộng năm bằng bao nhiêu?\n",
        "__label__hỏi_đáp Hai lần ba nhân chín chia ba bằng bao nhiêu?\n",
        "__label__hỏi_đáp Hai, tám, và chín có phải là số trung bình của bao nhiêu số không?\n",
        "__label__hỏi_đáp Tìm một số sao cho nếu cộng với bảy rồi chia cho ba thì kết quả là năm.\n",
        "__label__hỏi_đáp Tìm một số sao cho bảy lần số đó bằng bốn mươi chín.\n",
        "__label__hỏi_đáp Mười phần trăm của một trăm là bao nhiêu?\n",
        "__label__hỏi_đáp Nếu một số lớn hơn một số khác một phần trăm, số lớn hơn là bao nhiêu phần trăm của số nhỏ hơn?\n",
        "__label__hỏi_đáp So sánh 5/8 và 3/4. Số nào lớn hơn?\n",
        "__label__hỏi_đáp So sánh căn bậc hai của 16 và căn bậc hai của 25. Số nào lớn hơn?\n",
        "__label__hỏi_đáp So sánh 0.75 và 3/5. Số nào lớn hơn?\n",
        "__label__hỏi_đáp Một tam giác có bốn góc vuông và một góc nhọn. Tìm góc nhọn đó.\n",
        "__label__hỏi_đáp Nếu một chiếc xe chạy với vận tốc 60 km/h trong 3 giờ, hãy tính khoảng cách đã đi được.\n",
        "__label__hỏi_đáp Nếu một hình tròn có bán kính là 10 cm, hãy tính chu vi và diện tích của hình tròn đó.\n",
        "\n",
        "\"\"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kA3UXNiZMwx9"
      },
      "source": [
        "# Thực hành phân loại văn bản\n",
        "- Tải tập dữ liệu đã tiền xử lý về\n",
        "- Quan sát tập dữ liệu\n",
        "- Loại bỏ stopword\n",
        "\n",
        "- Xây dựng tập train/test\n",
        "\n",
        "- Phân loại văn bản sử dụng thuật toán Naive Bayes\n",
        "- Phân loại văn bản sử dụng thuật toán SVM\n",
        "- Phân loại văn bản sử dụng Fasttext\n",
        "\n",
        "- Tổng kết/ Nhận xét"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "aadjUdF8Mwx_",
        "outputId": "ab75d660-8d8e-4e52-9776-081880a96e85"
      },
      "outputs": [],
      "source": [
        "# Download data\n",
        "# Dữ liệu đã tiền xử lý có dạng: mỗi bài báo là một dòng, từ đầu tiên là nhãn (chủ đề) của dòng đó\n",
        "!wget -nc \"https://github.com/nguyenvanhieuvn/text-classification-tutorial/raw/master/news_categories.zip\"\n",
        "!unzip -n \"news_categories.zip\"\n",
        "!head \"news_categories.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jpZ60BlfMwyF",
        "outputId": "7832b310-c7ea-4dd2-e04a-12690af7039f",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "__label__hỏi_đáp 159\n",
            "__label__giá_cả 31\n",
            "__label__thời_tiết 51\n",
            "__label__nghe_nhạc 98\n",
            "__label__xem_video 31\n",
            "__label__tìm_đường 33\n",
            "__label__unknown 109\n"
          ]
        }
      ],
      "source": [
        "# Thống kê số lượng data theo nhãn\n",
        "count = {}\n",
        "with open('train_data.txt', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "# for line in open('train_data.txt'):\n",
        "        key = line.split()[0]\n",
        "        count[key] = count.get(key, 0) + 1\n",
        "\n",
        "for key in count:\n",
        "    print(key, count[key])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ClZ0AZOoMwyL",
        "outputId": "b1e7b2df-2cd7-4a34-ab26-6034d43e3880"
      },
      "outputs": [],
      "source": [
        "# Thống kê các word xuất hiện ở tất cả các nhãn\n",
        "total_label = 18\n",
        "vocab = {}\n",
        "label_vocab = {}\n",
        "for line in open('train_data.txt', encoding='utf-8'):\n",
        "    words = line.split()\n",
        "    # lưu ý từ đầu tiên là nhãn\n",
        "    label = words[0]\n",
        "    if label not in label_vocab:\n",
        "        label_vocab[label] = {}\n",
        "    for word in words[1:]:\n",
        "        label_vocab[label][word] = label_vocab[label].get(word, 0) + 1\n",
        "        if word not in vocab:\n",
        "            vocab[word] = set()\n",
        "        vocab[word].add(label)\n",
        "\n",
        "count = {}\n",
        "for word in vocab:\n",
        "    if len(vocab[word]) == total_label:\n",
        "        count[word] = min([label_vocab[x][word] for x in label_vocab])\n",
        "        \n",
        "sorted_count = sorted(count, key=count.get, reverse=True)\n",
        "for word in sorted_count[:16]:\n",
        "    print(word, count[word])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nL9ZaOgNMwyO"
      },
      "outputs": [],
      "source": [
        "# loại stopword khỏi dữ liệu\n",
        "# lưu file dùng về sau\n",
        "stopword = set()\n",
        "with open('stopwords.txt', 'w', encoding='utf-8') as fp:\n",
        "    for word in sorted_count[:100]:\n",
        "        stopword.add(word)\n",
        "        fp.write(word + '\\n')\n",
        "    \n",
        "def remove_stopwords(line):\n",
        "    words = []\n",
        "    for word in line.strip().split():\n",
        "        if word not in stopword:\n",
        "            words.append(word)\n",
        "    return ' '.join(words)\n",
        "    \n",
        "    \n",
        "with open('news_categories.prep', 'w', encoding='utf-8') as fp:\n",
        "    for line in open('train_data.txt', encoding='utf-8'):\n",
        "        line = remove_stopwords(line)\n",
        "        fp.write(line + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2C-K8a0qMwyR",
        "outputId": "ceaf0f2a-418f-4ed8-c0e1-16f95487a8b2"
      },
      "outputs": [],
      "source": [
        "!head news_categories.prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mVot0nxCMwyX",
        "outputId": "4b15729a-b4e3-423d-c482-6d826536af4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['__label__giá_cả', '__label__hỏi_đáp', '__label__nghe_nhạc', '__label__thời_tiết', '__label__tìm_đường', '__label__unknown', '__label__xem_video'] \n",
            "\n",
            "nghe bài hát liên_khúc trữ_tình của các ca_sĩ nổi_tiếng 2 \n",
            "\n",
            "chơi nhạc tặng anh cho cô ấy của khắc_việt 2\n"
          ]
        }
      ],
      "source": [
        "# Chia tập train/test\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import os\n",
        "labels_PATH = \"labels\"\n",
        "if not os.path.exists(labels_PATH):\n",
        "    os.makedirs(labels_PATH)\n",
        "\n",
        "test_percent = 0.2\n",
        "\n",
        "text = []\n",
        "label = []\n",
        "\n",
        "for line in open('news_categories.prep', encoding='utf-8'):\n",
        "    words = line.strip().split()\n",
        "    label.append(words[0])\n",
        "    text.append(' '.join(words[1:]))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(text, label, test_size=test_percent, random_state=42)\n",
        "\n",
        "# Lưu train/test data\n",
        "# Giữ nguyên train/test để về sau so sánh các mô hình cho công bằng\n",
        "with open('train.txt', 'w', encoding='utf-8') as fp:\n",
        "    for x, y in zip(X_train, y_train):\n",
        "        fp.write('{} {}\\n'.format(y, x))\n",
        "\n",
        "with open('test.txt', 'w', encoding='utf-8') as fp:\n",
        "    for x, y in zip(X_test, y_test):\n",
        "        fp.write('{} {}\\n'.format(y, x))\n",
        "\n",
        "# encode label\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "print(list(label_encoder.classes_), '\\n')\n",
        "\n",
        "with open('labels/label.txt', 'w', encoding='utf-8') as fp:\n",
        "    for label in list(label_encoder.classes_):\n",
        "        fp.write(label + '\\n')\n",
        "\n",
        "y_train = label_encoder.transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)\n",
        "\n",
        "print(X_train[0], y_train[0], '\\n')\n",
        "print(X_test[0], y_test[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MrGOKZILMwya"
      },
      "outputs": [],
      "source": [
        "MODEL_PATH = \"models\"\n",
        "\n",
        "import os\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    os.makedirs(MODEL_PATH)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JnRnrWcMMwyd"
      },
      "source": [
        "## Naive Bayes\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AkS3lqseMwye",
        "outputId": "3073eff8-0692-4bda-8f5b-333017981cf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done training Naive Bayes in 0.014508485794067383 seconds.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import time\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "start_time = time.time()\n",
        "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,1),\n",
        "                                             max_df=0.8,\n",
        "                                             max_features=None)), \n",
        "                     ('tfidf', TfidfTransformer()), \n",
        "                     ('clf', MultinomialNB())\n",
        "                    ])\n",
        "text_clf = text_clf.fit(X_train, y_train)\n",
        "\n",
        "train_time = time.time() - start_time\n",
        "print('Done training Naive Bayes in', train_time, 'seconds.')\n",
        "\n",
        "# Save model\n",
        "pickle.dump(text_clf, open(os.path.join(MODEL_PATH, \"naive_bayes.pkl\"), 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Flv2HtO2Mwyi"
      },
      "source": [
        "## Linear Classifier\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6vlilOMzMwyi",
        "outputId": "29a33424-25ed-441c-cbb2-7a6a5a1eb077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done training Linear Classifier in 0.06374478340148926 seconds.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "    \n",
        "start_time = time.time()\n",
        "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,1),\n",
        "                                             max_df=0.8,\n",
        "                                             max_features=None)), \n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', LogisticRegression(solver='lbfgs', \n",
        "                                                multi_class='auto',\n",
        "                                                max_iter=10000))\n",
        "                    ])\n",
        "text_clf = text_clf.fit(X_train, y_train)\n",
        "\n",
        "train_time = time.time() - start_time\n",
        "print('Done training Linear Classifier in', train_time, 'seconds.')\n",
        "\n",
        "# Save model\n",
        "pickle.dump(text_clf, open(os.path.join(MODEL_PATH, \"linear_classifier.pkl\"), 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V5DON6YQMwym"
      },
      "source": [
        "## Support Vector Machine (SVM)\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "G4z85ws5Mwyn",
        "outputId": "6cb33836-5f26-43d4-b0fc-536fc0b9fb7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done training SVM in 0.05431365966796875 seconds.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "start_time = time.time()\n",
        "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1,1),\n",
        "                                             max_df=0.8,\n",
        "                                             max_features=None)), \n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', SVC(gamma='scale'))\n",
        "                    ])\n",
        "text_clf = text_clf.fit(X_train, y_train)\n",
        "\n",
        "train_time = time.time() - start_time\n",
        "print('Done training SVM in', train_time, 'seconds.')\n",
        "\n",
        "# Save model\n",
        "pickle.dump(text_clf, open(os.path.join(MODEL_PATH, \"svm.pkl\"), 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iDDiZxH4Mwyq"
      },
      "source": [
        "## FastText\n",
        "https://github.com/facebookresearch/fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wEmOxmxNMwyr",
        "outputId": "de2173a1-9337-49e0-8220-fdf4314dd5d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in c:\\users\\dangd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.26.1)\n",
            "Requirement already satisfied: scipy in c:\\users\\dangd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.11.3)\n",
            "Requirement already satisfied: pybind11 in c:\\users\\dangd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.11.1)\n",
            "Requirement already satisfied: cmake in c:\\users\\dangd\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.27.7)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.0.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "The system cannot find the path specified.\n",
            "The system cannot find the path specified.\n",
            "The system cannot find the path specified.\n",
            "'rm' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# Cài đặt fastText cho Python\n",
        "!pip3 install --user numpy scipy pybind11 cmake\n",
        "!wget -nc \"https://github.com/facebookresearch/fastText/archive/v0.9.2.zip\" > /dev/null\n",
        "!unzip -n \"v0.9.2.zip\" > /dev/null\n",
        "!cd fastText-0.9.2 && pip3 install --user .\n",
        "!rm -rf v0.9.2.zip fastText-0.9.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "e_rhbogmMwyu",
        "outputId": "13667d71-91fd-4392-eefc-99ceb59b7eb5"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'fasttext'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32md:\\DOAN\\classification\\command_classification\\classification\\model_training\\text_classification_tutorial.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/DOAN/classification/command_classification/classification/model_training/text_classification_tutorial.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfasttext\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DOAN/classification/command_classification/classification/model_training/text_classification_tutorial.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DOAN/classification/command_classification/classification/model_training/text_classification_tutorial.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m fasttext\u001b[39m.\u001b[39mtrain_supervised(\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DOAN/classification/command_classification/classification/model_training/text_classification_tutorial.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                 \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain.txt\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/DOAN/classification/command_classification/classification/model_training/text_classification_tutorial.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                 dim\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DOAN/classification/command_classification/classification/model_training/text_classification_tutorial.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                                 minCount\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/DOAN/classification/command_classification/classification/model_training/text_classification_tutorial.ipynb#X25sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m )\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fasttext'"
          ]
        }
      ],
      "source": [
        "import fasttext\n",
        "\n",
        "start_time = time.time()\n",
        "model = fasttext.train_supervised(\n",
        "                                input='train.txt',\n",
        "                                dim=100,\n",
        "                                epoch=5,\n",
        "                                lr=0.1,\n",
        "                                wordNgrams=2,\n",
        "                                label='__label__',\n",
        "                                minCount=5\n",
        ")\n",
        "\n",
        "train_time = time.time() - start_time\n",
        "print('Done training Fasttext in', train_time, 'seconds.')\n",
        "\n",
        "# Compress model files with quantization\n",
        "model.quantize(input='train.txt', retrain=True)\n",
        "model.save_model(os.path.join(MODEL_PATH,\"fasttext.ftz\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UuSOImTRMwyy"
      },
      "source": [
        "## Đánh giá các mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0K04GPknMwyy",
        "outputId": "8d51e838-bafe-4a1e-a34c-38b36a0d2458"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes, Accuracy = 0.8640776699029126\n",
            "Linear Classifier, Accuracy = 0.9223300970873787\n",
            "SVM, Accuracy = 0.9029126213592233\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# Naive Bayes\n",
        "model = pickle.load(open(os.path.join(MODEL_PATH,\"naive_bayes.pkl\"), 'rb'))\n",
        "y_pred = model.predict(X_test)\n",
        "print('Naive Bayes, Accuracy =', np.mean(y_pred == y_test))\n",
        "\n",
        "# Linear Classifier\n",
        "model = pickle.load(open(os.path.join(MODEL_PATH,\"linear_classifier.pkl\"), 'rb'))\n",
        "y_pred = model.predict(X_test)\n",
        "print('Linear Classifier, Accuracy =', np.mean(y_pred == y_test))\n",
        "\n",
        "# SVM\n",
        "model = pickle.load(open(os.path.join(MODEL_PATH,\"svm.pkl\"), 'rb'))\n",
        "y_pred = model.predict(X_test)\n",
        "print('SVM, Accuracy =', np.mean(y_pred == y_test))\n",
        "\n",
        "# Fasttext\n",
        "# def print_results(N, p, r):\n",
        "#     print(\"Fasttext, Precision = {}, Recall = {}\".format(p, r))\n",
        "    \n",
        "# model = fasttext.load_model(os.path.join(MODEL_PATH,\"fasttext.ftz\"))\n",
        "# print_results(*model.test('test.txt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "o3KXn7zEMwy1",
        "outputId": "ffe4898d-a0dd-4b26-e944-67529128398f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                    precision    recall  f1-score   support\n",
            "\n",
            "   __label__giá_cả       1.00      1.00      1.00        11\n",
            "  __label__hỏi_đáp       0.59      1.00      0.74        16\n",
            "__label__nghe_nhạc       0.74      1.00      0.85        14\n",
            "__label__thời_tiết       1.00      1.00      1.00        11\n",
            "__label__tìm_đường       1.00      1.00      1.00         6\n",
            "  __label__unknown       0.00      0.00      0.00        21\n",
            "__label__xem_video       0.44      1.00      0.62         4\n",
            "\n",
            "          accuracy                           0.75        83\n",
            "         macro avg       0.68      0.86      0.74        83\n",
            "      weighted avg       0.60      0.75      0.65        83\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\dangd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\dangd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\dangd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Xem kết quả trên từng nhãn\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "nb_model = pickle.load(open(os.path.join(MODEL_PATH,\"svm.pkl\"), 'rb'))\n",
        "y_pred = nb_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, target_names=list(label_encoder.classes_)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                    precision    recall  f1-score   support\n",
            "\n",
            "   __label__giá_cả       1.00      0.82      0.90        11\n",
            "  __label__hỏi_đáp       0.90      0.56      0.69        16\n",
            "__label__nghe_nhạc       0.93      1.00      0.97        14\n",
            "__label__thời_tiết       0.85      1.00      0.92        11\n",
            "__label__tìm_đường       1.00      1.00      1.00         6\n",
            "  __label__unknown       0.70      0.90      0.79        21\n",
            "__label__xem_video       1.00      0.75      0.86         4\n",
            "\n",
            "          accuracy                           0.86        83\n",
            "         macro avg       0.91      0.86      0.87        83\n",
            "      weighted avg       0.87      0.86      0.85        83\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "nb_model = pickle.load(open(os.path.join(MODEL_PATH,\"linear_classifier.pkl\"), 'rb'))\n",
        "y_pred = nb_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, target_names=list(label_encoder.classes_)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "78sdWuRjMwy5",
        "outputId": "d5d878b3-dd9b-4cfe-ec88-efb51a3bddb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predict label: ['__label__unknown']\n"
          ]
        }
      ],
      "source": [
        "# xem kết quả cho 1 văn bản model naive bayes đã load ở trên\n",
        "\n",
        "document = \"thời tiết ở hà nội video hoa hướng dương\"\n",
        "\n",
        "document = text_preprocess(document)\n",
        "document = remove_stopwords(document)\n",
        "\n",
        "label = nb_model.predict([document])\n",
        "print('Predict label:', label_encoder.inverse_transform(label))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "text_classification_tutorial.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
